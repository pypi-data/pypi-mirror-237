{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'activations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# Assemble a few models to test\u001b[39;00m\n\u001b[0;32m     12\u001b[0m net_atan  \u001b[39m=\u001b[39m mc\u001b[39m.\u001b[39mAdvNet(\u001b[39m1\u001b[39m, [\u001b[39m25\u001b[39m], \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39matan\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m net_lin   \u001b[39m=\u001b[39m mc\u001b[39m.\u001b[39;49mAdvNet(\u001b[39m1\u001b[39;49m, [\u001b[39m25\u001b[39;49m], \u001b[39m1\u001b[39;49m)\n\u001b[0;32m     14\u001b[0m net_combo \u001b[39m=\u001b[39m mc\u001b[39m.\u001b[39mAdvNet(\u001b[39m1\u001b[39m, [\u001b[39m25\u001b[39m], \u001b[39m1\u001b[39m, [\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39melu\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlin\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     16\u001b[0m \u001b[39m# An equal alternative definition for the ATAN model:\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# net_atan = AdvNet(1, [25], 1, ['atan', 'atan', 'atan'])\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[39m# Train-Test Split (Taking only the train group)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'activations'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mcnets as mc\n",
    "\n",
    "# Data to fit to (f(x) = x^0.5)\n",
    "# You can increase the number of samples by changing the X variable\n",
    "X = np.random.rand(20)*2 # Gives domain of [0, 2)\n",
    "Y = X**0.5\n",
    "\n",
    "# Assemble a few models to test\n",
    "net_atan  = mc.AdvNet(1, [25], 1, 'atan')\n",
    "net_lin   = mc.AdvNet(1, [25], 1)\n",
    "net_combo = mc.AdvNet(1, [25], 1, ['relu', 'elu', 'lin'])\n",
    "\n",
    "# An equal alternative definition for the ATAN model:\n",
    "# net_atan = AdvNet(1, [25], 1, ['atan', 'atan', 'atan'])\n",
    "\n",
    "# An equal alternative definition for the linear model (lin is default):\n",
    "# net_atan = AdvNet(1, [25], 1)  \n",
    "\n",
    "# Train-Test Split (Taking only the train group)\n",
    "x, y, _, _ = mc.TTSplit(X, Y, percentTrain=50)\n",
    "\n",
    "# Fit the models to the training data group\n",
    "print(\"ATAN Model Training:\")\n",
    "net_atan  = net_atan.Fit(x, y)\n",
    "\n",
    "print(\"\\nLinear Model Training:\")\n",
    "net_lin   = net_lin.Fit(x, y)\n",
    "\n",
    "print(\"\\nCombo Model Training\")\n",
    "net_combo = net_combo.Fit(x, y)\n",
    "\n",
    "# Get the models predictions to the full data set\n",
    "ym_atan  = net_atan.Predict(X)\n",
    "ym_lin   = net_lin.Predict(X)\n",
    "ym_combo = net_combo.Predict(X)\n",
    "\n",
    "# Plot and compare the results of the models\n",
    "print(\"\\nPlotted Results:\")\n",
    "plt.plot(Y, 'o')\n",
    "plt.plot(ym_atan, 'r--')\n",
    "plt.plot(ym_lin, 'g--')\n",
    "plt.plot(ym_combo, 'b--')\n",
    "plt.title(f\"y=x^0.5 vs Networks of Various Activation Functions\")\n",
    "plt.legend([\"True Data\", \"ATAN Model\", \"Linear Model\", \"Combo Model\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 7], [8, 15]] [[0, 4], [5, 8], [9, 12]]\n"
     ]
    }
   ],
   "source": [
    "# CNN Tests\n",
    "inputXSize = 16\n",
    "inputYSize = 13\n",
    "\n",
    "# Make divisions based on odd/evenness\n",
    "def MakeRange(inSize:int):\n",
    "    dom = []\n",
    "    if inSize%2 == 0:\n",
    "        step = inSize//2\n",
    "        for i in range(2):\n",
    "            dom.append([step*i, step*(i+1)-1])\n",
    "    else:\n",
    "        adjust = 0\n",
    "        step = inSize//3\n",
    "        rem = inSize - step*3\n",
    "        for i in range(3):\n",
    "            if rem > 0:\n",
    "                dom.append([step*i+adjust, step*(i+1)+adjust])\n",
    "                rem -= 1\n",
    "                adjust += 1\n",
    "            else:\n",
    "                dom.append([step*i+adjust, step*(i+1)-1+adjust])\n",
    "    return dom\n",
    "\n",
    "xRanges = MakeRange(inputXSize)\n",
    "yRanges = MakeRange(inputYSize)\n",
    "\n",
    "print(xRanges, yRanges)\n",
    "\n",
    "# Get XY matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.485287111336854\n",
      "1.485287111336854\n",
      "\n",
      "0.0\n",
      "0.020818701594728047\n",
      "\n",
      "1.401918200000182\n",
      "1.5869154999998045\n"
     ]
    }
   ],
   "source": [
    "# Microtweak tests\n",
    "import matplotlib.pyplot as plt\n",
    "from main import *\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import math as m\n",
    "from time import perf_counter as pc\n",
    "\n",
    "# Functions\n",
    "def getMAE(net:AdvNet, X, Y):\n",
    "    # Get Mean/Average Error\n",
    "    netVals = Forecast(net, X, plotResults=False)\n",
    "    MAE = 0\n",
    "    for yhi, yi in zip(netVals, Y):\n",
    "        MAE += abs(yhi-yi)\n",
    "    MAE = MAE/len(netVals)\n",
    "    return MAE\n",
    "\n",
    "def clip(val:float, minVal, maxVal):\n",
    "    if val > maxVal:\n",
    "        return maxVal\n",
    "    elif val < minVal:\n",
    "        return minVal\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "def gradientTrain(net:AdvNet, X, Y, itrs:int):\n",
    "    # Loop design\n",
    "    # 1 - Get current error\n",
    "    # 2 - Test error after increasing and decreasing a single weight\n",
    "    # 3 - Set net to new best, move on to next weight\n",
    "    #       - ****ASSUME NET IS 2 LAYERS TOTAL****\n",
    "    #       - Stop loop if improvement is small enough\n",
    "\n",
    "    # Cycle loop to change tuning precision over time\n",
    "    for I in range(round(itrs)):\n",
    "        # Get current tuning precision\n",
    "        gamma = 2 / (I + 1)\n",
    "\n",
    "        # Iterate over the net weight arrays\n",
    "        # This shouldnt be needed for this functions purpose\n",
    "        # Still included as a general solution\n",
    "        for WI, weightArr in enumerate(net.weights):\n",
    "            # Iterate over the net individual weights\n",
    "            for i, wi in enumerate(weightArr):\n",
    "                # Get starting error/change\n",
    "                bestMAE = getMAE(net, X, Y)\n",
    "                dW = abs(2 * (rn.random() - 0.5) * gamma)\n",
    "\n",
    "                # Test change up\n",
    "                Wup = clip(wi + dW, -1, 1)\n",
    "                net.weights[WI][i] = Wup\n",
    "                upMAE = getMAE(net, X, Y)\n",
    "\n",
    "                # Test change down\n",
    "                Wdown = clip(wi - dW, -1, 1)\n",
    "                net.weights[WI][i] = Wdown\n",
    "                downMAE = getMAE(net, X, Y)\n",
    "\n",
    "                # Apply best weight\n",
    "                errors = [bestMAE, upMAE, downMAE]\n",
    "                wiList = [wi, Wup, Wdown]\n",
    "                bestIndex = errors.index(min(errors))\n",
    "                net.weights[WI][i] = wiList[bestIndex]\n",
    "    \n",
    "    return net, min(errors)\n",
    "        \n",
    "# Data\n",
    "net = AdvNet(4, [], 1, \"lin\")\n",
    "X = 4 * (np.random.rand(100, 4) - 0.5)\n",
    "Y = np.zeros((100,))\n",
    "for i, xi in enumerate(X):\n",
    "    Y[i] = np.sum(xi)\n",
    "\n",
    "# # Do tests\n",
    "net1 = net.CopyNet()\n",
    "net2 = net.CopyNet()\n",
    "\n",
    "print(getMAE(net1, X ,Y))\n",
    "print(getMAE(net2, X, Y))\n",
    "print()\n",
    "\n",
    "t1 = pc()\n",
    "net1, r2 = genTrain(net1, X, Y, iterations=10,\n",
    "                    batchSize=100, gamma=1, Silent=True)\n",
    "\n",
    "t2 = pc()\n",
    "\n",
    "net2, MAE = gradientTrain(net2, X, Y, itrs=100)\n",
    "t3 = pc()\n",
    "\n",
    "print(getMAE(net1, X ,Y))\n",
    "print(getMAE(net2, X, Y))\n",
    "print()\n",
    "\n",
    "print(t2-t1)\n",
    "print(t3-t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 1.000000 | Training: ========================================\n",
      "R2: 1.000000 | Training: ========================================\n",
      "R2: 1.000000 | Training: ========================================\n",
      "Normal Method:\n",
      "5.8331 Seconds\n",
      "R2: 1.000000 | Training: ========================================R2: 0.999996 | Training: =========-------------------------------\n",
      "R2: 1.000000 | Training: ========================================\n",
      "R2: 1.000000 | Training: ========================================\n",
      "Threaded Method:\n",
      "5.6816 Seconds\n"
     ]
    }
   ],
   "source": [
    "# Threading Tests\n",
    "from main import *\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "from time import perf_counter as pc\n",
    "\n",
    "net1 = AdvNet(1, [5], 1, \"lin\")\n",
    "net2 = AdvNet(1, [10], 1, \"lin\")\n",
    "net3 = AdvNet(1, [15], 1, \"lin\")\n",
    "\n",
    "X = np.linspace(0, 2, 200)\n",
    "Y = np.linspace(0, 2, 200)\n",
    "\n",
    "# Normal way\n",
    "t1 = pc()\n",
    "genTrain(net1, X, Y, iterations=10,\n",
    "         batchSize=50, gamma=1, R2Goal=1)\n",
    "genTrain(net2, X, Y, iterations=10,\n",
    "         batchSize=50, gamma=1, R2Goal=1)\n",
    "genTrain(net3, X, Y, iterations=10,\n",
    "         batchSize=50, gamma=1, R2Goal=1)\n",
    "t2 = pc()\n",
    "\n",
    "print(\"Normal Method:\")\n",
    "print(f\"{format(t2-t1, '.4f')} Seconds\")\n",
    "\n",
    "# Threaded way\n",
    "t3 = pc()\n",
    "T1 = Thread(target=genTrain, args=(net1, X, Y), \n",
    "            kwargs={'iterations':10, 'batchSize':50, 'gamma':1, 'R2Goal':1})\n",
    "T2 = Thread(target=genTrain, args=(net2, X, Y), \n",
    "            kwargs={'iterations':10, 'batchSize':50, 'gamma':1, 'R2Goal':1})\n",
    "T3 = Thread(target=genTrain, args=(net3, X, Y), \n",
    "            kwargs={'iterations':10, 'batchSize':50, 'gamma':1, 'R2Goal':1})\n",
    "\n",
    "T1.start()\n",
    "T2.start()\n",
    "T3.start()\n",
    "\n",
    "T1.join()\n",
    "T2.join()\n",
    "T3.join()\n",
    "t4 = pc()\n",
    "\n",
    "print(\"Threaded Method:\")\n",
    "print(f\"{format(t4-t3, '.4f')} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Score: 16.307604159500553\n",
      "\n",
      "Score 1: 11.745016447379008\n",
      "Score 2: 11.738644745022901\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\Documents (Cloud)\\Hobby Things\\Codes\\~~~PyPi\\NeuralNet\\src\\mcnets\\Feature Experiments.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Documents%20%28Cloud%29/Hobby%20Things/Codes/~~~PyPi/NeuralNet/src/mcnets/Feature%20Experiments.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m newScore \u001b[39m=\u001b[39m best \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Documents%20%28Cloud%29/Hobby%20Things/Codes/~~~PyPi/NeuralNet/src/mcnets/Feature%20Experiments.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mwhile\u001b[39;00m newScore \u001b[39m>\u001b[39m best:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive/Documents%20%28Cloud%29/Hobby%20Things/Codes/~~~PyPi/NeuralNet/src/mcnets/Feature%20Experiments.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     net2 \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mCopyNet()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Documents%20%28Cloud%29/Hobby%20Things/Codes/~~~PyPi/NeuralNet/src/mcnets/Feature%20Experiments.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     net2\u001b[39m.\u001b[39mTweakWeights(\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Documents%20%28Cloud%29/Hobby%20Things/Codes/~~~PyPi/NeuralNet/src/mcnets/Feature%20Experiments.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     newScore \u001b[39m=\u001b[39m getScore(xData, yTrue, net2)\n",
      "File \u001b[1;32md:\\OneDrive\\Documents (Cloud)\\Hobby Things\\Codes\\~~~PyPi\\NeuralNet\\src\\mcnets\\main.py:315\u001b[0m, in \u001b[0;36mAdvNet.CopyNet\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[39m# Setup weights\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(newSizes) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m--> 315\u001b[0m     newNet\u001b[39m.\u001b[39mweights[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights[i]\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m    317\u001b[0m \u001b[39m# Return the copied net\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[39mreturn\u001b[39;00m newNet\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Gradient Tests\n",
    "size = 3\n",
    "acts = [\"ATAN\"]\n",
    "net = AdvNet(1, [15]*(size-1), 1, [rn.choice(acts) for _ in range(size)])\n",
    "\n",
    "# Data\n",
    "xData = np.arange(0, 3, 0.5).tolist()\n",
    "yTrue = [(xi+(rn.random()-0.5))**2 for xi in xData]\n",
    "\n",
    "# Functions\n",
    "def getScore(X, Y, NN):\n",
    "    yHat = [NN.Calculate(xi) for xi in X]\n",
    "    diffs = [abs(yi-yhi) for yi, yhi in zip(Y, yHat)]\n",
    "    return sum(diffs)\n",
    "\n",
    "# Training\n",
    "# Initial Score\n",
    "best = getScore(xData, yTrue, net)\n",
    "bestCopy = best\n",
    "print(f\"Initial Score: {best}\\n\")\n",
    "\n",
    "# Training (Standard single batch)\n",
    "for i in range(3):\n",
    "    newScore = best + 1\n",
    "    while newScore > best:\n",
    "        net2 = net.CopyNet()\n",
    "        net2.TweakWeights(1/(i+1))\n",
    "        newScore = getScore(xData, yTrue, net2)\n",
    "    best = newScore\n",
    "    print(f\"Score {i+1}: {best}\")\n",
    "print()\n",
    "\n",
    "# Training (gradient)\n",
    "print(\"With Gradient:\")\n",
    "dW = None\n",
    "for i in range(3):\n",
    "    newScore = bestCopy + 1\n",
    "    if dW == None:\n",
    "        while newScore > bestCopy:\n",
    "            net3 = net.CopyNet()\n",
    "            dW = net3.TweakWeights(1/(i+1), returnChange=True)\n",
    "            newScore = getScore(xData, yTrue, net3)\n",
    "    else:\n",
    "        for _ in range(20):\n",
    "            done = False\n",
    "            dW = [wi/(1.05) for wi in dW]\n",
    "            net3 = net.CopyNet()\n",
    "            net3.ApplyTweak(dW)\n",
    "            newScore = getScore(xData, yTrue, net3)\n",
    "            if newScore < bestCopy:\n",
    "                done = True\n",
    "                print(\"Used Gradient\")\n",
    "                break\n",
    "        if not done:\n",
    "            while newScore > bestCopy:\n",
    "                net3 = net.CopyNet()\n",
    "                dW = net3.TweakWeights(1/(i+1), returnChange=True)\n",
    "                newScore = getScore(xData, yTrue, net3)\n",
    "    bestCopy = newScore\n",
    "    print(f\"Score {i+1}: {bestCopy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d1e45cadc3597bb8b6600530fbdf8c3eefe919a24ef54d9d32b318795b772e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
