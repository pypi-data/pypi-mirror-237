{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from buckaroo.buckaroo_widget import BuckarooWidget, disable, enable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88e3983a0d54d1baab75e24ad7d5dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BuckarooWidget(commandConfig={'argspecs': {'dropcol': [None], 'to_datetime': [None], 'safeint': [None], 'fillnâ€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/paddy/code/citibike-play/2014-01 - Citi Bike trip data.csv')[:205]\n",
    "#df\n",
    "#df\n",
    "#bw = BuckarooWidget(df[:10_000])\n",
    "bw = BuckarooWidget(df)\n",
    "bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.widgetConfig = {'showCommands': True, 'showTransformed': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = dict(a = 5, b =10)\n",
    "ab.copy().update(dict(a=3, c=20))\n",
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.summary_stats import summarize_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = summarize_df(df2)\n",
    "#sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df['start station latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = df['start station latitude']\n",
    "ab.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min([1,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('1971-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(1_00_000_000_000_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('1973-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probable_datetime(ser):\n",
    "    s_ser = ser.sample(np.min([len(ser), 500]))\n",
    "    try:\n",
    "        dt_ser = pd.to_datetime(s_ser)\n",
    "        #pd.to_datetime(1_00_000_000_000_000_000) == pd.to_datetime('1973-01-01') \n",
    "        if dt_ser.max() < pd.to_datetime('1973-01-01'):\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False\n",
    "#probable_datetime(df['start station name'])\n",
    "[[col, probable_datetime(df[col])] for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df['start station name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize_column(ser):\n",
    "    if pd.api.types.is_numeric_dtype(ser.dtype):\n",
    "        return ser\n",
    "    else:\n",
    "        return make_num_categorical(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def without(arr, search_keys):\n",
    "    new_arr = []\n",
    "    for v in arr:\n",
    "        if v not in search_keys:\n",
    "            new_arr.append(v)\n",
    "    return new_arr\n",
    "\n",
    "def all_duplicates(raw_corr_pairs):\n",
    "    flatlist = reduce(lambda a,b:a+b, raw_corr_pairs.values())\n",
    "    return set(flatlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_num_categorical(ser):\n",
    "    ser_uniq = ser.unique()\n",
    "    name_to_idx = {name:idx for idx, name in enumerate(ser_uniq)}\n",
    "    #needs to be vectorized\n",
    "    num_categorical = ser.apply(lambda x:name_to_idx[x])\n",
    "    return num_categorical\n",
    "\n",
    "def get_cor_pair_dict(df, summary_stats):\n",
    "    #we need to remove columns with only nans or a single value, they mess up corr()\n",
    "\n",
    "    #this needs to be vectorized\n",
    "    corrable_cols = [col for col in df if summary_stats[col]['distinct_count'] > 1]\n",
    "    #print(\"corrable_cols\", corrable_cols)\n",
    "    #num_df =  pd.DataFrame({col:numerize_column(df[col]) for col in corrable_cols})\n",
    "\n",
    "    num_df =  pd.DataFrame({col:make_num_categorical(df[col]) for col in corrable_cols})\n",
    "\n",
    "    corr_df = num_df.corr()\n",
    "    high_corr_df = corr_df[corr_df > 0.99]\n",
    "    cor_dict = {}\n",
    "    for col in high_corr_df.columns:\n",
    "        #columns with high correlation that aren't the column itself\n",
    "        other_cor_cols = high_corr_df[col].dropna().drop(col)\n",
    "        cor_cols = other_cor_cols.index.values\n",
    "        if len(cor_cols) > 0:\n",
    "            cor_dict[col] = cor_cols.tolist()\n",
    "    return cor_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = make_num_categorical(df2['start station id'])\n",
    "bc = make_num_categorical(df2['start station name'])\n",
    "cd = make_num_categorical(df2['start station latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id':ab, 'name':bc, 'lat':cd, 'bikeid': make_num_categorical(df2['bikeid'])}).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cor_pair_dict(df2, sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd = get_cor_pair_dict(df2, sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_directional_dict(raw_corr_pair):\n",
    "    # convert from two way links to only one way based on first seen\n",
    "    seen = []\n",
    "    ret_corr_pair = {}\n",
    "    for key, other_key_list in raw_corr_pair.items():\n",
    "        seen.append(key)\n",
    "        stripped_other = without(other_key_list, seen)\n",
    "        if len(stripped_other) > 0:\n",
    "            ret_corr_pair[key] = stripped_other\n",
    "    return ret_corr_pair\n",
    "\n",
    "\n",
    "def all_duplicates(raw_corr_pairs):\n",
    "    flatlist = reduce(lambda a,b:a+b, raw_corr_pairs.values())\n",
    "    return set(flatlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_groupings(corr_pairs):\n",
    "    all_groupings = []\n",
    "    for key, other_key_list in corr_pairs.items():\n",
    "        ab = other_key_list.copy()\n",
    "        ab.append(key)\n",
    "        all_groupings.append(set(ab))\n",
    "    return np.unique(all_groupings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupings = find_groupings(cpd)\n",
    "groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_groupings(grps, ranked_cols):\n",
    "    first_cols, rest_cols = [], []\n",
    "    for col in ranked_cols:\n",
    "        for grp in grps:\n",
    "            if col in grp:\n",
    "                first_cols.append(col)\n",
    "                rest_cols.extend(list(without(grp, [col])))\n",
    "                grps = without(grps, [grp])\n",
    "    return first_cols, rest_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_groupings(groupings, ['start station name', 'end station name', 'stoptime', 'starttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_directional_dict(cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_groupings(corr_pairs):\n",
    "    all_groupings = []\n",
    "    for key, other_key_list in corr_pairs.items():\n",
    "        ab = other_key_list.copy()\n",
    "        ab.append(key)\n",
    "        all_groupings.append(set(ab))\n",
    "    return np.unique(all_groupings)\n",
    "def order_groupings(grps, ranked_cols):\n",
    "    first_cols, rest_cols = [], []\n",
    "    for col in ranked_cols:\n",
    "        for grp in grps:\n",
    "            if col in grp:\n",
    "                first_cols.append(col)\n",
    "                rest_cols.extend(list(without(grp, [col])))\n",
    "                grps = without(grps, [grp])\n",
    "    return first_cols, rest_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.getipython import get_ipython\n",
    "from IPython.display import display\n",
    "ip = get_ipython()\n",
    "ip_formatter = ip.display_formatter.ipython_display_formatter\n",
    "ip_formatter.type_printers.pop(pd.DataFrame, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_numeric_dtype(ser.dtype):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_integer_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[pd.api.types.is_integer_dtype(df2[col]) for col in df2.columns]\n",
    "[pd.api.types.is_numeric_dtype(df2[col]) for col in df2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdf = sdf.copy()\n",
    "tsdf.loc['first_col'] = 0\n",
    "tsdf.loc['first_col':, ['starttime', 'start station name']] = 5\n",
    "tsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "set_when(sdf.copy(), 'is_integer', 'grouping_score_integer', -3, 0)\n",
    "\n",
    "#only_ones = (sdf.loc['distinct_count'] <= 1)\n",
    "#    sdf.loc['one_distinct', only_ones[only_ones==True].index.values] = -20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_when(tsdf, 'is_integer', 'grouping_score_integer', -3, 0)\n",
    "set_when(tsdf, 'is_numeric', 'grouping_score_numeric', -3, 5)\n",
    "grouping_col_scores = tsdf.loc[['grouping_score_integer', 'grouping_score_numeric']].sum()\n",
    "# col_scores.sort_values().index.values[::-1]\n",
    "\n",
    "grouping_col_scores.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_col_scores.sort_values().index[::-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "def set_when(df, cond_row_name, target_row_name, true_val, false_val):\n",
    "    true_row = df.loc[cond_row_name]\n",
    "    df.loc[target_row_name] = false_val\n",
    "    df.loc[target_row_name, true_row[true_row==True].index.values] = true_val\n",
    "    return df\n",
    "\n",
    "def all_duplicates(raw_corr_pairs):\n",
    "    flatlist = reduce(lambda a,b:a+b, raw_corr_pairs.values())\n",
    "    return set(flatlist)\n",
    "\n",
    "def find_groupings(corr_pairs):\n",
    "    all_groupings = []\n",
    "    for key, other_key_list in corr_pairs.items():\n",
    "        ab = other_key_list.copy()\n",
    "        ab.append(key)\n",
    "        all_groupings.append(set(ab))\n",
    "    return np.unique(all_groupings)\n",
    "def order_groupings(grps, ranked_cols):\n",
    "    first_cols, rest_cols = [], []\n",
    "    for col in ranked_cols:\n",
    "        for grp in grps:\n",
    "            if col in grp:\n",
    "                first_cols.append(col)\n",
    "                rest_cols.extend(list(without(grp, [col])))\n",
    "                grps = without(grps, [grp])\n",
    "    return first_cols, rest_cols\n",
    "\n",
    "def order_columns(summary_stats_df, corr_pair_dict):\n",
    "    sdf = summary_stats_df.copy()\n",
    "    sdf.loc['one_distinct'] = 0\n",
    "\n",
    "    only_ones = (sdf.loc['distinct_count'] <= 1)\n",
    "    sdf.loc['one_distinct', only_ones[only_ones==True].index.values] = -20\n",
    "    \n",
    "    sdf.loc['first_col'] = 0\n",
    "    sdf.loc['is_duplicate'] = 0\n",
    "    \n",
    "    set_when(sdf, 'is_integer', 'grouping_score_integer', -3, 0)\n",
    "    set_when(sdf, 'is_numeric', 'grouping_score_numeric', -3, 5)\n",
    "    grouping_col_scores = sdf.loc[['grouping_score_integer', 'grouping_score_numeric']].sum()\n",
    "    duplicate_col_rankings = grouping_col_scores.sort_values().index[::-1].values\n",
    "\n",
    "    groupings = find_groupings(corr_pair_dict)\n",
    "    first_cols, duplicate_cols = order_groupings(groupings, duplicate_col_rankings)\n",
    "    \n",
    "    sdf.loc['first_col':, first_cols] = 5\n",
    "    sdf.loc['is_duplicate':, duplicate_cols] = -5\n",
    "    \n",
    "    col_scores = sdf.loc[['one_distinct', 'first_col', 'is_duplicate']].sum()\n",
    "    return col_scores.sort_values().index.values[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_columns(sdf, cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd = get_cor_pair_dict(df2, sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_columns(sdf, cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.getipython import get_ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.getipython import get_ipython\n",
    "from IPython.display import display\n",
    "ip = get_ipython()\n",
    "ip_formatter = ip.display_formatter.ipython_display_formatter\n",
    "def _display_as_buckaroo(df):\n",
    "    return display(BuckarooWidget(df))\n",
    "ip_formatter.for_type(pd.DataFrame, _display_as_buckaroo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _display_as_buckaroo(df):\n",
    "    return display(BuckarooWidget(df))\n",
    "ip_formatter.for_type(pd.DataFrame, _display_as_buckaroo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_formatter.for_type(pd.DataFrame, _display_as_buckaroo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(BuckarooWidget(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.dfConfig['sampled'] = False\n",
    "bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(df, sample_size=500, include_outliers=True):\n",
    "    \n",
    "    sample_size = np.min([sample_size, len(df)])\n",
    "    sdf = df.sample(sample_size)\n",
    "    \n",
    "    \n",
    "    if include_outliers:\n",
    "        outlier_idxs = []\n",
    "        for col in df.columns:\n",
    "            idxs = df[col].sort_values().index\n",
    "            outlier_idxs.extend(idxs[:5])\n",
    "            outlier_idxs.extend(idxs[-5:])\n",
    "        outlier_idxs.extend(sdf.index)\n",
    "        uniq_idx = np.unique(outlier_idxs)\n",
    "        #print(uniq_idx)\n",
    "        return df.iloc[uniq_idx]\n",
    "    return sdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sample(df, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sample(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sample(df, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[23,58, 1023]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./examples/data/2014-01-citibike-tripdata.csv')\n",
    "w = BuckarooWidget(df)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = df['tripduration']\n",
    "ab.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ab = ab.sort_values()\n",
    "sorted_ab.index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique([2,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start station name'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([2,2,3]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a.extend([23,45], [32,5])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = df.sample(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [2,3]\n",
    "arr.extend(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[137, 137, 138]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df.iloc[sorted_ab.index[:5]], df[20:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.all_transforms import Command\n",
    "from buckaroo.lispy import s\n",
    "#Here we start adding commands to the Buckaroo Widget.  Every call to add_command replaces a command with the same name\n",
    "@w.add_command\n",
    "class GroupBy2(Command):\n",
    "    command_default = [s(\"groupby2\"), s('df'), 'col', {}]\n",
    "    command_pattern = [[3, 'colMap', 'colEnum', ['null', 'sum', 'mean', 'median', 'count']]]\n",
    "    @staticmethod \n",
    "    def transform(df, col, col_spec):\n",
    "        grps = df.groupby(col)\n",
    "        df_contents = {}\n",
    "        for k, v in col_spec.items():\n",
    "            if v == \"sum\":\n",
    "                df_contents[k] = grps[k].apply(lambda x: x.sum())\n",
    "            elif v == \"mean\":\n",
    "                df_contents[k] = grps[k].apply(lambda x: x.mean())\n",
    "            elif v == \"median\":\n",
    "                df_contents[k] = grps[k].apply(lambda x: x.median())\n",
    "            elif v == \"count\":\n",
    "                df_contents[k] = grps[k].apply(lambda x: x.count())\n",
    "        return pd.DataFrame(df_contents)\n",
    "\n",
    "    @staticmethod \n",
    "    def transform_to_py(df, col, col_spec):\n",
    "        commands = [\n",
    "            \"    grps = df.groupby('%s')\" % col,\n",
    "            \"    df_contents = {}\"\n",
    "        ]\n",
    "        for k, v in col_spec.items():\n",
    "            if v == \"sum\":\n",
    "                commands.append(\"    paddydf_contents['%s'] = grps['%s'].apply(lambda x: x.sum())\" % (k, k))\n",
    "            elif v == \"mean\":\n",
    "                commands.append(\"    df_contents['%s'] = grps['%s'].apply(lambda x: x.mean())\" % (k, k))\n",
    "            elif v == \"median\":\n",
    "                commands.append(\"    df_contents['%s'] = grps['%s'].apply(lambda x: x.median())\" % (k, k))\n",
    "            elif v == \"count\":\n",
    "                commands.append(\"    df_contents['%s'] = grps['%s'].apply(lambda x: x.count())\" % (k, k))\n",
    "        commands.append(\"    df = pd.DataFrame(df_contents)\")\n",
    "        return \"\\n\".join(commands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
